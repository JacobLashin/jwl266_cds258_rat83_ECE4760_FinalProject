<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Jacob-lashin-3400-project : ">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>ECE 4760 Final Project</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <h1 id="project_title">ECE 4760 Final Project</h1>
          <h2 id="project_tagline">Jacob Lashin, Romano Tio, Christopher Schiff</h2>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1>
          Introduction
        </h1>
        <div style="background: lightgray; 
            font-size: 20px; 
            padding: 10px; 
            border: 1px solid black; 
            margin: 10px;
            border-radius: 10px;">
            For our project, we designed a system to generate sheet music based upon inputs detected by a microphone and processed by our microcontroller.
        </div>
        <p style="text-indent: 40px">
          To accomplish this, we utilized an FFT, designed a note categorization system, and used this system to generate corresponding MIDI messages that can be processed by a digital audio workstation. We also investigated the prospect of utilizing a machine-learning model to improve the note categorization process.
        </p>
        <br>
        <br>
        <h1>
          High-Level Design
        </h1>
        <img src="hardwareLayout.png" alt="Hardware Layout">
        <p style="text-indent: 40px">
          Our project is split into three major parts: frequency identification, note classification, and MIDI conversion. In order to accomplish audio identification, we utilize a microphone and ADC converter to feed audio information into a fixed-point implementation of an FFT. The fixed point implementation was provided to us by Dr. Adams earlier on in the semester, however, we changed it slightly so that we could detect every peak instead of just one maximum frequency. From the output of the FFT, we implemented note classification which classifies bins from FFT that met certain conditions into actual music notes. In order for a sound to be classified, its respective bin from the FFT must reach a certain threshold, chosen by us through observation, so that we do not incorrectly detect and classify noise as a viable note. Additionally, the respective bin must be a peak, meaning it must have the largest magnitude in comparison to its neighbors. This requirement gives us the functionality to not make the mistake of classifying several notes at once.
        </p>
        <p style="text-indent: 40px">
          Once those requirements are met, we can then actually classify the bins we have detected in our sound as notes. On startup, we populate a table full of notes and their respective frequency. In order to classify notes, we compare the frequency of the sound heard to those of the frequencies in the note lookup table. We do this by comparing the difference between the bin and each frequency in our lookup table iteratively, and retaining the index of the note which has the least distance between itself and the bin under examination. That index can then be used to return the actual note played and which octave it is played in.
        </p>
        <br>
        <br>
        <h1>
          Hardware Design
        </h1>
        <p></p>
        <br>
        <br>
        <h1>
          Software Design
        </h1>
        <p></p>
        <br>
        <br>
        <h1>
          Conclusions
        </h1>
        <p></p>
        <br>
        <br>
        <h1>
          Live Demo
        </h1>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/c4soAzSzYtE"></iframe>
        <br>
        <br>
        <h1>
          Appendix
        </h1>
        <p></p>
        <br>
        <br>
        <h1>
          References
        </h1>
        <ul>
          <li><a href="http://www.music.mcgill.ca/~ich/classes/mumt306/StandardMIDIfileformat.html#BMA1_">Source used for our MIDI file generation</a></li>
          <li><a href="https://ece4760.github.io/">Hunter Adams' ECE 4760 course site</a></li>
        </ul>
        <br>
        <br>
  </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">jwl266_cds258_rat83_ECE4760_FinalProject maintained by <a href="https://github.com/JacobLashin/jwl266_cds258_rat83_ECE4760_FinalProject">JacobLashin</a></p>
      </footer>
    </div>
  </body>
</html>
